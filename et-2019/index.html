<!doctype html>
<html lang="en">

<!--
-->

	<head>
		<meta charset="utf-8">

		<title>Numerical Neutron Star Modelling</title>

		<meta name="description" content="Einstein Toolkit Workshop, London, September 2019">
		<meta name="author" content="Ian Hawke">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="../reveal.js/css/reveal.css">
		<link rel="stylesheet" href="../reveal.js/css/theme/black.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--MathJax stuff -->
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}, TeX: { extensions: ["autobold.js"] }});
		</script>
		<script type="text/javascript"
		  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		<!--PDF print -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->

		<!--Left align-->
		<style type="text/css">
			.reveal p { text-align: left; }
			.reveal ol,
			.reveal dl,
			.reveal ul {
			  display: block;
			  text-align: left;
			  margin: 0 0 0 1em; }
			.reveal h1 {
				text-transform: none;
				line-height: 2.0
			}
			.reveal h2,
			.reveal h3,
			.reveal h4 {
				text-transform: none;
			}
			.reveal table td {
				border-bottom: none;
			}
			.reveal.slide .slides > section, .reveal.slide .slides > section > section {
			  min-height: 100% !important;
			  display: flex !important;
			  flex-direction: column !important;
			  justify-content: center !important;
			  position: absolute !important;
			  top: 0 !important;
			  align-items: center !important;
			}
			section > h1, section > h2 {
			  position: absolute !important;
			  top: 0 !important;
			  margin-left: auto !important;
			  margin-right: auto !important;
			  left: 0 !important;
			  right: 0 !important;
			  text-align: center !important;
			}
			.print-pdf .reveal.slide .slides > section, .print-pdf .reveal.slide .slides > section > section {
			  min-height: 770px !important;
			  position: relative !important;
			}
		</style>
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

				<section id="title">

					<section data-background="figures/background.jpg" data-background-position="center" data-background-size="100%" data-background-color="#000000">
						<div style="float: center">
							<h1 style="line-height: 1.0">Numerical Neutron Star <del>Muddling</del> Modelling</h1>
							<p>
								<ul style="list-style: none;">
									<li> Ian Hawke
								</ul>
							</p>
							<p>
								<ul style="list-style: none;">
									<li> <a href="http://twitter.com/ianhawke">@IanHawke</a>
									<li> <a href="http://https://github.com/IanHawke">github.com/IanHawke</a>
									<li> <a href="http://orcid.org/0000-0003-4805-0309">orcid.org/0000-0003-4805-0309</a>
									<li> STAG, University of Southampton
								</ul>
							</p>
						</div>
						<aside class="notes">
							Thanks for the invitation
						</aside>
					</section>

				</section>

				<section id="Motivation">

					<section data-background="figures/g1701866-v5-q-transform-30-1col-cside.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>GW170817</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								The only NS merger seen in GWs:
								<ol>
									<li> high SNR;
									<li> covers frequencies from 10s-1000s Hz;
                  <li> observed in multiple detectors, allowing localisation.
								</ol>
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href="https://dx.doi.org/10.1103/PhysRevLett.121.191102"> LIGO, arxiv:</a>
							</p>
						</div>

						<aside class="notes">
							GW170817 is the ony fully confirmed and checked GW signal of a BNS merger. In a staggering stroke of luck only seen when thousands collaborate over decades, the strongest GW signal yet detected was the (relatively) close merger of two neutron stars, giving us strong field information about their interior physics.
							<br>
							A crucial point to note here is that LIGO has observed the merger from about 50 up to 500 Hz: in principle we expect the signal to span from tens to a few thousands of Hz.
						</aside>
					</section>

					<section data-background="figures/bns_figure4.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>GW170817</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								NS constraints from GWs:
								<ol>
									<li> Mass $\sim 1.4 M_{\odot}$;
									<li> Radius $\sim 11 \pm 1 \text{ km}$;
                  <li> weak constraints on EOS through tidal compressibility.
								</ol>
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href="https://dx.doi.org/10.1103/PhysRevLett.121.191102"> LIGO, arxiv:</a>
							</p>
						</div>

						<aside class="notes">
							Getting more information about the properties of matter in extreme situations is one key purpose of GW observations of NS mergers. Much of this information is expressed through the <i>equation of state</i>, a short-hand for how the microscopic properties affect large scale observables (for example, how the hydrodynamic pressure depends on density and temperature). The mass information doesn't tell us anything that wasn't known from pulsars, but the radius information is much harder to get that way. Information about the tidal compressibility, via the Love numbers, put constraints on the equation of state that are complementary to that from pulsar observations.
						</aside>
					</section>

				</section>

				<section id="Multi messenger">

					<section data-background="figures/SD_hp_pol_vs_IF_lowmass.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>GWs and observables</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								Expect LIGO to <i>only</i> see GWs from inspiral. Need lower noise at higher frequencies to see
								<ol>
									<li> post-merger signal, needed for "seismology";
									<li> supernova signals;
                  <li> information about final fate of object.
								</ol>
								Need third generation detectors (Einstein Telescope).
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href="https://dx.doi.org/10.1103/PhysRevLett.121.191102"> LIGO, arxiv:</a>
							</p>
						</div>

						<aside class="notes">
							This figure is from one of the Einstein Telescope design studies, overlaying expected GW signals on various detector noise curves. It emphasizes how lucky GW170817 was - that was at around 40Mpc, whereas here we're looking at the expected distance of 300Mpc. The key point is that it's the inspiral phase that hits the sweet spot of LIGO's noise curve. The higher frequency part of the signal is practically unobservable with LIGO; we'd need better detectors to get those.
							<br>
							The Einstein Telescope is one such third generation detector; that's likely at least 20 years in the future. LIGO is good enough for the inspiral: to get more information about the physics we'll need either to wait, or do something else.
						</aside>
					</section>

					<section data-background="figures/timeline-with-spectrum-amgv7.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>Multi messenger astronomy</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								Want to complement GW observations with
								<ol>
									<li> electromagnetic signals (radio, X-ray, $\gamma$, ...);
									<li> neutrino observations;
                  <li> anything else we can get.
								</ol>
								Done with GW170817: inferred jet properties suggest more constraints on progenitors.
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href="https://dx.doi.org/10.1103/PhysRevLett.121.191102"> LIGO, arxiv:</a>
							</p>
						</div>

						<aside class="notes">
							Multi messenger is going to be the key approach until third generation detectors come online. Using complementary observation channels we can get further information to constrain the microscopic properties. This isn't new: neutrino and EM observations have been combined for studies of the sun, and for supernovae. By including GWs we're getting constraints on the coupling between gravity and matter. It's hard to do: localising the source just from GWs is tricky with so few detectors, especially fast enough (even with GW170817 the first trigger was in $\gamma$!), but improving the network will help (eg, LIGO India).
							<br>
							For GW170817 there's a wealth of information about the post-merger regime, particularly the jet pushed out by the kilonova and the products left over. This gives some weak constraints on the constituents of the progenitor NSs. These constraints will be strengthened by further observations in O3 and beyond: was Sunday's event (1st September) another BNS merger?
						</aside>
					</section>

				</section>

				<section id="Modelling">

					<section data-background="figures/nstar_plot_stage3.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>Modelling: inspiral</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								For inspiral only bulk properties matter:
								<ul>
									<li> mass;
									<li> spin;
									<li> compactness (EOS);
									<li> bulk internal magentic field.
								</ul>
								Leads to key numerical limits:
								<ul>
									<li> $\lambda_{\text{GW}} \sim 10^6 \text{ m} \implies L_{\text{grid}} \sim 10^7 \text{ m}$;
									<li> $R_{\text{NS}} \sim 10^4 \text{ m} \implies $\Delta x \sim 100 \text{ m}$.
									<li> Stability: $\Delta x \sim 100 \text{ m} \implies \Delta t \sim 10^{-6} \text{ s}$.
								</ul>
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href=""> Steiner.</a>
							</p>
						</div>

						<aside class="notes">
							The inspiral phase is driven by the spacetime effects. There's practially no interaction between the NSs until the very final phase (but see the part about the crust later!). So the crucial quantities and leading order in the stress-energy, and we can write them down quite simply: total mass-energy (through baryon mass and magnetic fields), compactness, and (for longer inspirals) the effects of spin and eccentricity. This is very close to the situation for BHs.
							<br>
							From this we can determine the key numbers for numerical simulations. We saw from the plots for GW170817 that the GW frequencies run from tens to thousands of Hz. If we focus on the last fractions of a second, where the frequencies are in the hundreds of Hz and which are all we can practially simulate, then that corresponds to a gravitational wavelength of order $10^6$ m. To get enough GWs into our grid to measure we'll need multiple wavelengths, so a grid boundary at order $10^7$ m.
							<br>
							Similarly, we know that the NS radius is of order $10^4$ m. We'll need many tens of points across the radius to accurately capture the behaviour over the timescale of the merger, leading to a grid spacing of order $100$ m. Causality leads to the stability constraint (CFL!) meaning the timestep can't be bigger than $10^{-6}$ s. For evolving say $10$ ms that's $10^4$ steps at best.
						</aside>
					</section>

					<section data-background="figures/ShibataUryu99.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>How far have we come?</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								Shibata & UryÅ« 1999:
								<ul>
									<li> just polytropes;
									<li> boundary at $\sim 0.3 \lambda_{\text{GW}};
									<li> $\Delta x \sim 600 \text{ m}$.
								</ul>
								Kiuchi & Shibata 2017:
								<ul>
									<li> MHD, "real" EOS;
									<li> boundary at $\sim XX \lambda_{\text{GW}}$
									<li> $\Delta x \sim 12 \text{ m}$.
								</ul>
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href=""> Steiner.</a>
							</p>
						</div>

						<aside class="notes">
							There's been a big jump in modelling in the past 20 years. The work of Shibata and collaborators sets much of the standards and we can see how the early test simulations which don't meet the required standards for LIGO are now replaced by simulations definitely good enough for second generation detectors.
							<br>
							It's worth noting that at around this time the work of the Binary NS and BH Grand Challenges were bearing fruit, with the open GR3D code leading, through Mark Miller's MAHC code and the EU Network Whisky code, to the GRHydro code that's available through the ETK today.
						</aside>
					</section>

					<section data-background="figures/NStar_both.png" data-background-position="right" data-background-size="90%">
						<div style="width: 90%">
							<h1>How far must we go?</h1>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href=""> Steiner.</a>
							</p>
						</div>

						<aside class="notes">
							As we move to higher resolution we have to look at the NS modelling. Here are images from Page and Steiner looking at some of the additional physics that are going to have some level of impact on the observed signals. There's the crust and the layered nature of the star. There's the magnetic field, which has to consistently extend through the interior to the exterior. There's the exotic particles in the core, and the superfluid neutron fluids. There's a wealth of complex interactions with emitted radiation. A lot of these effects happen on short length or timescales so are unlikely to impact the inspiral, but the multi messenger post-merger signals will crucially depend on these details.
						</aside>
					</section>

					<section data-background="figures/NStar_both.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>Elastic crust</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								Outer layers of NS form a "crust"
								<ul>
									<li> $L_{\text{crust}} \sim 10^{2}-10^{3} \text{ m}$;
									<li> EOS "known"; strain and fracture less so;
									<li> precursor shattering (Tsang)?
								</ul>
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href=""> Steiner.</a>
							</p>
						</div>

						<aside class="notes">
							In the outer layers it's energetically favourable for the neutrons to form a lattice. The effects on the bulk motion are small - for example, the Love numbers (and hence tidal compressibility) change at the sub-percent level. However, the magnetic field is expected to be tightly bound to the crust, and mismatches between crustal and core motion and expected to generate observable signals. This is seen in pulsars via glitches; Tsang has suggested that inspiral resonances may shatter the crust leading to EM observable signals, giving detailed EOS information.
							<br>
							To simulate this we'll need a formulation and $\Delta x \sim 10$ m.
						</aside>
					</section>

					<section data-background="figures/NStar_both.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>Non-ideal effects</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								Many sources:
								<ul>
									<li> Bulk and shear viscosity;
									<li> EM resistivity;
									<li> Magnetic turbulence;
									<li> ...
								</ul>
								Crucial for interior (angular momentum transport) and exterior (heat and EM propagation).
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href=""> Steiner.</a>
							</p>
						</div>

						<aside class="notes">
							There's a broad range of length and timescales for non-ideal effects. Estimates from Alford and collaborators suggest shear viscosity could matter if there's significant gradients on lengthscales of order $10$ m, and bulk viscosity could be important in all current simulations. Going beyond ideal MHD is needed to consistently connect the interior and exterior of the NS, obviously needed for multi-messenger: it's likely that the lengthscales involved here are of the order of $1$ m, making things tricky.
							<br>
							The short/fast scales involved here mean we'll either need to be smart with our numerics or approximate the model in some way.
						</aside>
					</section>

					<section data-background="figures/NStar_both.png" data-background-position="right" data-background-size="50%">
						<div style="width: 90%">
							<h1>Superfluids</h1>
						</div>
						<div style="float: left; width: 49%">
							<p>
								Modelling suggests
								<ul>
									<li> neutrons may Cooper pair: superfluids;
									<li> flux tubes may form: superconductivity;
									<li> details remain very uncertain!
								</ul>
							</p>
						</div>
						<div style="position: absolute; bottom: 5px; right: 5px; width: 49%">
							<p>
								<a href=""> Steiner.</a>
							</p>
						</div>

						<aside class="notes">
							There remains some dispute that effects that, on earth, are micro-scale quantum level with small-scale macro effects, like superconductivity and superfluidity, even exist on the kilometre lengthscales of a NS. However, it's strongly believed that Cooper pairing will lead to some part of the outer core and inner crust over a radius of at least metres will contain these effects. This has crucial for angular momentum transport - the quantization of rotation is inherent, and also leads to anisotropic heat transport and could have a massive effect of cooling of the remnant.
							<br>
							However, consistent hydrodynamic theories of, eg, superfluids, involve multiple inter-penetrating fluids with their own velocity vectors. The lengthscales could be relevant for all simulations - the flux tubes and vortices could stretch across the whole NS! - but the timescales where things relax could be extremely short.
						</aside>
					</section>

				</section>

				<section id="Numerics">

					<section>
						<div>
							<h1>Conservation</h1>

							<p>
								EFEs imply $\nabla_a T^{ab} = 0$. Pick a tetrad, $e_b^{(j)}$ to get
								$$
								\begin{aligned}
								  && \nabla_a \left[ e_b^{(j)} T^{ab} \right] &= \tfrac{1}{\sqrt{-g}} \partial_a \left( \sqrt{-g} e_b^{(j)} T^{ab} \right) = -T^{ab} \nabla_a e_b^{(j)} \\
									\implies && \partial_t {\bf q} + \partial_i {\bf f}^{(i)}({\bf q}) &= {\bf s}.
								\end{aligned}
								$$
								Balance law form.

								Only four equations: need other constituitive equations for, eg, EM, particle number, etc.
							</p>
						</div>

						<aside class="notes">
							Starting from stress-energy conservation we can choose a tetrad, typically aligned with the coordinates, to get four balance laws. The crucial point is the total divergence on the left-hand-side. First order hyperbolic PDEs of this form are well studied, and there's good numerical methods to solve them.

							However, for astrophysically interesting matter we're going to need more than four fields to describe it. The conserved quantities (the ${\bf q}$'s) are roughly the energy and momentum of the average flow. We'll also need to describe EM fields, radiation, temperature and particle number by additional fields. These may be in balance law form, but may not (as seen in the multifluid section).
						</aside>
					</section>

					<section data-background="figures/Books.png" data-background-position="right" data-background-size="90%">
						<div style="width: 90%">
							<h1>Methods</h1>
						</div>

						<aside class="notes">
							Balance law form is standard in CFD: from Godunov in the 1950s to van Leer in the 1970s, the methods we use have a long pedigree. The field, driven by the Valencia group through the 1990s, caught up by 2005. As long as we have the balance law form we can evolve the system with confidence, as we'll see with Bruno's talk.
						</aside>
					</section>

					<section data-background="figures/RMRFinalStatePressure.jpg" data-background-position='right' data-background-size="55%">
						<div style="float: left; width: 40%">
							<h1>Non-ideal effects</h1>
							<p>
								Example of magnetic resistivity:
								<ul>
									<li>
										width of features depends on resistivity;
									</li>
									<li>
										source terms "stiff": stability of full model requires $\Delta t \sim \sigma^{-1}$;
									</li>
									<li>
										can approximate model by perturbation expansion about ideal MHD.
									</li>
								</ul>
							</p>
						</div>
						<aside class="notes">
							Non-ideal effects are usually very small. Unfortunately, "usually" is not good enough: the NS surface, for example, depends crucially on non-ideal effects. In the "full" non-ideal models the additional terms usually come in through the sources, and are often "stiff": that is, they react by trying the "push" the system back to an equilibrium, and they do this on very fast timescales. That's problematic, as the evolution needs to resolve these short/fast scales in order to remain stable.
							<br>
							This example is from resistive MHD. If ideal MHD were used then the "islands" of magnetic pressure should stay separate. By including resistivity magnetic reconnection causes them to interact, with the width of the boundary layer linked to the resistivity value. As we get closer to "real" values of the resistivity you can see the connection region getting very thin.
						</aside>
					</section>

					<section data-background='figures/BWandReconnectionOptPerf3DIHTalk.jpg' data-background-position='bottom' data-background-size="100%">
						<div style="float: top">
							<h1>Performance</h1>
							<p>
								Either use stable numerics or approximate model.
							</p>
						</div>
						<aside class="notes">
							There are two approaches to the stiffness problem. One is to use implicit numerical methods. This allows us to evolve the full model, stably, but has significant computational costs - in these examples it's usually an order of magnitude, and for real values it will only get worse.
							<br>
							The alternative is to approximate the model, which we do here by a perturbation expansion about the ideal MHD limit. This "Chapman-Enskog" expansion was designed for the Boltzmann equation, so has broader relevance. The performance is much better than the implicit methods, but there are some stability issues: the approximation is only stable for certain resolutions.
						</aside>
					</section>

				</section>

				<section id="Summary">

				</section>

<!--
					<section>
						<div style="float: left; width: 50%">
							<h1>Matter</h1>
							<p>
								Matter simulations:
								<ol>
									<li> have shocks;
									<li> "turbulence";
									<li> more observables;
									<li> little on well-posedness.
								</ol>
							</p>
							<p>
								Can we get reliable predictions?
							</p>
						</div>
						<div style="float: right; width: 50%">
							<img src="figures_ih/KiuchiDensityVorticity.png" />
							<p>
								<a href="https://dx.doi.org/10.1103/PhysRevD.92.124034"> Kiuchi et al, 1509.09205</a>
							</p>
						</div>

						<aside class="notes">
							Life gets more complicated with matter simulations, where the fluid shocks formed in mergers can interact with features on ever smaller scales, which we often call "turbulence" even when working with ideal models. This image from the amazing simulations of Kiuchi and collaborators highlights that. For multi-messenger situations we're going to care about observables driven by local features of the fluid and magnetic field, so we're going to need to need robust predictions of the local values of the matter quantities.
							<br>
							Unfortunately global well-posedness results for matter systems, even without GR, are hard to come by.
						</aside>
					</section>




				</section>

				<section id="Well-posedness">

					<section id="Kelvin-Helmholtz-ID" data-background="figures_ih/kh_plot_id.png" data-background-position="bottom" data-background-size="85%">
						<div style="float: top; width: 100%">
							<h1>Kelvin-Helmholtz instability</h1>
						</div>
						<aside class="notes">
							The Kelvin-Helmholtz instability is a simple analogue for the wind-up of vorticity and magnetic fields that happens during binary neutron star mergers. The matter on either side of the layer slips past each other, with the high relative velocities leading to vortex generation. Carefully setting up the initial data is a crucial point for code comparisons, with one of the standard approaches being to smooth the density transition whilst perturbing the transverse velocity. Here, instead, I'm following Fjordholm and Mishra by keeping the transition sharp and perturbing the location of the transition layer.
							<br>
							This is crucial because the question we want to ask is directly related to the uncertainty quantification we want to do. The question is: are the Euler equations well-posed?
						</aside>
					</section>

					<section id="Kelvin-Helmholtz-res" data-background="figures_ih/kh_rho_all_1234.png" data-background-position="right" data-background-size="55%">
						<div style="float: left; width: 44%">
							<h1>Lax</h1>
						  <p>
								<ul>
									<li> Code consistent;
									<li> Numerics stable;
									<li> No convergence.
								</ul>
							</p>
							<p>
								Lax's theorem means the system is <i>not</i> well-posed.
              </p>
						</div>
						<aside class="notes">
							To check well-posedness, Fjordholm and Mishra use Lax's theorem. In the standard form that says "for a well-posed system, consistency plus stability is equivalent to convergence". By using multiple numerical codes where we are confident of consistency, and where stability is obvious, the failure of the numerics to converge implies the continuum system is not well-posed. I'm showing this visually with my results using Mike Zingale's `pyro` code, where we see the gross features are similar, but there is clearly no pointwise convergence; in Fjordholm and Mishra's papers they show more detailed convergence measures.
							<br>
							So, if the system isn't well-posed, this destroys any hope of estimating parameters using the standard approach.
						</aside>
					</section>

				</section>

				<section id="Statistical solutions">

					<section>
						<div style="float: left; width: 90%">
							<h1>Saving convergence</h1>
							<p>
								We don't see convergence to <i>weak solutions</i> of
								$$
								  \partial_t q + \partial_i f^{(i)}(q) = s(q).
								$$
							</p>
							<p>
								Instead use a spacetime-dependent probability measure $\nu$ solving
								$$
								  \partial_t \langle \nu, \text{id} \rangle  + \partial_{i} \langle \nu, f^{(i)} \rangle = \langle \nu, s \rangle.
								$$
							</p>
							<p>
								Need to ensure appropriate entropy solution and small scale features.
							</p>
						</div>
						<aside class="notes">
							This crucial point of Fjordholm and Mishra's work isn't to show problems, but to present a potential solution. Their approach is to change what we think of as a solution. We've already done this to solve Euler's equations in the first place: to account for shocks we have to talk about weak, distributional solutions. To get around the well-posedness issues Fjordholm and Mishra weaken the solution still further: we now consider probability measures at every single point of space and time, and force the measure to evolve in a manner consistent with our equations of motion. There are additional technical restrictions that need imposing. In particular the measure needs to obey and entropy condition in a similar fashion to a standard weak solution. Secondly, the solution needs to be "not too turbulent".
						</aside>
					</section>

					<section id="MC1" data-background="figures_ih/kh_plot_128_realizations_512.png" data-background-position="bottom" data-background-size="90%">
						<div style="header">
							<h1>Constructing the measure</h1>
						</div>
						<aside class="notes">
							To numerically compute the probability measure that is the statistical solution we can use a Monte-Carlo algorithm. Here we're not doing anything clever: we modify the initial data by changing (pseudo-randomly) the perturbation in the location of the initial interface. Here I'm showing 128 realizations at a fixed resolution, which we can use to look at statistical properties of the solution.
						</aside>
					</section>

					<section id="MC2" data-background="figures_ih/kh_mean_var_all.png" data-background-position="right" data-background-size="70%">
						<div style="float: left; width: 29%">
							<h1>$\mathbb{E}$ & var</h1>
							<p>
								Both mean and variance clearly converge.
							</p>
							<p>
								Characterize the uncertainty in the observable.
							</p>
						</div>
						<aside class="notes">
							Here I'm plotting the pointwise mean over all the realizations. You can visually see rapid convergence with resolution, but all cases are qualitatively similar. The characteristic Kelvin-Helmholtz vortices are gone, but there is now (on average) a transition layer between the high and low density regions.
							<br>
							Crucially by measuring the variance we can start to characterize the uncertainty in the observable. In this case we can do it on a pointwise basis, and see that, as we would expect, the variance is mostly small except in the transition layer. Characterizing what's going on in this "turbulent" region is the hard part.
						</aside>
					</section>

					<section id="MC3" data-background="figures_ih/var_mean_kde_256_plot1.png" data-background-position="right" data-background-size="60%">
						<div style="float: left; width: 39%">
							<h1>PDF</h1>
							<p>
								Can directly estimate the PDF, eg along a line. These also converge rapidly.
							</p>
							<p>
								Some features not obvious from $\mathbb{E}$ and variance.
							</p>
						</div>
						<aside class="notes">
							We can directly estimate the probability distribution function. Here I'm taking advantage of the symmetry to do it along lines. We can see how the distribution changes through the transition layer. There's peaks corresponding to the two densities in the initial data clearly visible: that's at around $\rho=1$ and $2$. However, there's a third intermediate peak that wouldn't be obvious from the mean and variance alone.
						</aside>
					</section>

					<section id="MC4" data-background="figures_ih/rho_pdfs_all.png" data-background-position="bottom" data-background-size="77%">
						<aside class="notes">
							Here are the PDFs converging with both resolution and the number of realizations. This is just along one line, but again Fjordholm, Mishra and collaborators have detailed statistical convergence measures in their papers.
						</aside>
					</section>

					<section>
						<div style="header">
							<h1>Quantifying the problem</h1>
						</div>
						<div style="float: left; width: 90%">
							<p>
								For "standard" case, measure numerical error as
								$$
								  {\cal E} \simeq C_1 (\Delta x)^s.
								$$
							</p>
							<p>
								For statistical solutions, simple Monte-Carlo, expect
								$$
								  {\cal E} \simeq C_1 (\Delta x)^s + C_2 M^{-1/2}.
								$$
							</p>
							<p>
								Measure $C_i$'s, see what error dominates. If variance large, prediction hard!
							</p>
						</div>
						<aside class="notes">
							To bring it back to numbers, the point here is to quantify the uncertainty of a numerical prediction of an observable within a given model. Typically we would quantify the numerical uncertainty through the truncation error. This gives us a value at a point in parameter space, up to the numerical error.
							<br>
							Instead, with statistical solutions, we have all the statistical moments, up to the numerical error of the simulation, and the numerical error from only doing a finite number of realizations. We now have a probability measure at a point in parameter space, which can be used against the observations. In most regions the truncation error will dominate, but in cases like we've seen here - shocks interacting with "turbulence" - the realization error and the intrinsic variance may dominate instead. It's essential to quantify this before using such simulations in parameter estimation.
						</aside>
					</section>

				</section>
-->
				<section id="Summary">

					<section>
						<div class="header">
							<h1>Summary</h1>
						</div>
						<p>
							<ul>
								<li>Blah
							</ul>
						</p>
						<aside class="notes">
							Blah
						</aside>
					</section>

				</section>

			</div>

		</div>

		<script src="../reveal.js/js/reveal.js"></script>

		<script>
			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
        controlsTutorial: false,
        overview: true,
				progress: true,
        hash: true,
				history: true,
				center: false,
				width:  1366,
				height: 768,
				// showNotes = true,
				margin: 0.05,
				transition: 'none', // none/fade/slide/convex/concave/zoom
        backgroundTransition: 'none',
				// Parallax background image
			    //parallaxBackgroundImage: '../../figures/hs-2009-05-a-full_jpg.jpg', // e.g. "https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg"
			    // Parallax background size
			    //parallaxBackgroundSize: '2145px 1213px', // CSS syntax, e.g. "2100px 900px" - currently only pixels are supported (don't use % or auto)
			    // Amount of pixels to move the parallax background per slide step,
			    // a value of 0 disables movement along the given axis
			    // These are optional, if they aren't specified they'll be calculated automatically
			    //parallaxBackgroundHorizontal: 200,
			    //parallaxBackgroundVertical: 50
				math: {
			        mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js',
			        config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
			    },
				// Optional reveal.js plugins
				dependencies: [
					{ src: '../reveal.js/plugin/math/math.js', async: true },
					{ src: '../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../reveal.js/plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../reveal.js/plugin/zoom-js/zoom.js', async: true },
					{ src: '../reveal.js/plugin/notes/notes.js', async: true }
				]
			});
		</script>
	</body>
</html>
