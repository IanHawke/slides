{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854399c5",
   "metadata": {},
   "source": [
    "# Bulk viscosity and boundary layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_width = (7.68, 4.8)\n",
    "half_width = (3.84, 4.8)\n",
    "half_double = (7.68, 9.6)\n",
    "plt.rcParams['figure.figsize'] = half_width # 50% of the screen, vertical, assuming a 1x2 plot\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# plt.rcParams.update({'font.size': 16,\n",
    "#                      'lines.markersize': 12,\n",
    "#                      'lines.markeredgewidth': 2})\n",
    "save_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca085e",
   "metadata": {},
   "source": [
    "This is like the boundary layers notebook, but with the equations modified to the relativistic case (minor tweak), and figures plotted in talk format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92a8c4",
   "metadata": {},
   "source": [
    "## Bulk viscosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557bd04",
   "metadata": {},
   "source": [
    "Take the relativistic Euler equations in convective form. Assume that we are looking on a sufficiently small scale so that gradients of the pressure are negligible and the divergence of the velocity is constant. Include the effects of a reaction term. Then the equations of motion become\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_t \\rho &= - \\rho \\theta \\\\\n",
    "D_t e &= -(e + p(\\rho, e, Y)) \\theta \\\\\n",
    "D_t Y &= -\\epsilon^{-1} \\Gamma(\\rho, e, Y).\n",
    "\\end{aligned}\n",
    "$$\n",
    "Here $\\theta = \\nabla \\cdot v$ is the (constant) expansion and $\\epsilon \\ll 1$ is the reaction timescale, whilst $D_t$ is the convective derivative.\n",
    "\n",
    "To simplify the system we linearize the reaction rate $\\Gamma$ as $\\Gamma = A(\\rho, e) Y - B(\\rho, e)$ and assume that $B / A > 0$ so there is a stable equilibrium solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f89e2",
   "metadata": {},
   "source": [
    "The simplest multiscale calculation makes the assumption that\n",
    "$$\n",
    "Y = \\sum_{n=0} \\epsilon^n Y_n.\n",
    "$$\n",
    "Substituting into the equation of motion for the species fraction,\n",
    "$$\n",
    "D_t Y = -\\epsilon^{-1} \\left( A Y - B \\right),\n",
    "$$\n",
    "and gathering like powers in $\\epsilon$, we find\n",
    "$$\n",
    "Y_0 = \\frac{B}{A} = Y_{\\text{eq}}(\\rho, e)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Y_1 = -A^{-1} D_t Y_0 = A^{-1} \\left( \\rho \\partial_\\rho Y_{\\text{eq}}+ (e + p_{\\text{eq}}) \\partial_e Y_{\\text{eq}} \\right) \\theta.\n",
    "$$\n",
    "From this we can expand the pressure in powers of $\\epsilon$ about equilibrium, finding\n",
    "$$\n",
    "p = p(\\rho, e, Y_{\\text{eq}}) + \\epsilon \\left. \\partial_Y p \\right|_{\\text{eq}} Y_1 = p + \\Pi,\n",
    "$$\n",
    "where the bulk viscosity $\\Pi = - \\zeta \\theta$, and the bulk viscosity coefficient is\n",
    "$$\n",
    "\\zeta = -\\epsilon \\left. \\partial_Y p \\right|_{\\text{eq}} A^{-1} \\left( \\rho \\partial_\\rho Y_{\\text{eq}} + (e + p_{\\text{eq}}) \\partial_e Y_{\\text{eq}} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed09cc",
   "metadata": {},
   "source": [
    "The advantages of the bulk viscosity approach is that the stiffness problem (due to the $\\epsilon^{-1}$ term is the evolution equation for $Y$) has vanished (as all bulk viscosity terms have non-negative powers of $\\epsilon$), and the number of equations of motion has reduced. The complexity of the system has slightly increased, however. As a whole, we expect the bulk viscous addition to be simpler and faster to solve numerically, particularly when $\\epsilon \\to 0$.\n",
    "\n",
    "**Note**. An odd, and somewhat concerning, feature here is that (under minimal assumptions about the equilibrium) the bulk viscosity coefficient is negative. This is because the equilibrium pressure is not the true hydrostatic/thermodynamic pressure: that is instead the full $p$. As $\\Pi$ turns up on the opposite side of the equality to the true thermodynamic pressure, the sign works in the opposite direction. We may want to re-consider the conventions here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85045ff5",
   "metadata": {},
   "source": [
    "### Checking the accuracy of the approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa71976",
   "metadata": {},
   "source": [
    "The calculation above can be checked for formal accuracy as a function of $\\epsilon$. \n",
    "\n",
    "The leading order case is where the pressure is simply replaced with the equilibrium pressure. This is the \"infinitely fast reaction\" case. It should be first order accurate as a function of $\\epsilon$. That is, given any observable slow variable (such as $e$) at a time $\\mathcal{O}(1)$, the difference between the observable computed by the full system including the reaction term and using the full pressure, and computed with the reduced system that does not included the reaction term and evaluates the pressure at equilibrium, should be proportional to $\\epsilon$.\n",
    "\n",
    "The next order case is where the reduced system includes the bulk viscous term. It should be second order accurate as a function of $\\epsilon$: the difference to the full system should be proportional to $\\epsilon^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1370b",
   "metadata": {},
   "source": [
    "We check this numerically by specifying an explicit equation of state, reaction rate, and initial data. We choose\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p &= Y \\rho e \\\\\n",
    "A &= e \\\\\n",
    "B &= \\frac{\\rho}{3} \\\\\n",
    "\\rho(0) &= 1 \\\\\n",
    "e(0) &= 1 \\\\\n",
    "\\theta &= 1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "From this it follows that\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Y_{\\text{eq}} &= \\frac{\\rho}{3 e} \\\\\n",
    "\\partial_\\rho Y_{\\text{eq}} &= \\frac{1}{3 e} \\\\\n",
    "\\partial_e Y_{\\text{eq}} &= -\\frac{\\rho}{3 e^2} \\\\\n",
    "p_{\\text{eq}} &= \\frac{\\rho^2}{3} \\\\\n",
    "\\left. \\partial_Y p \\right|_{\\text{eq}} &= \\rho e \\\\\n",
    "\\zeta &= -\\epsilon \\frac{\\rho^2}{3 e} \\left( 1 - \\frac{3e + \\rho^2}{3 \\rho e} \\right).\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49826fd",
   "metadata": {},
   "source": [
    "We can now solve the system explicitly in three cases:\n",
    "\n",
    "1. the full system;\n",
    "2. the infinitely fast reaction approximation;\n",
    "3. the bulk viscous approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 1\n",
    "rho0 = 1\n",
    "e0 = 1\n",
    "\n",
    "def Y_eq(rho, e):\n",
    "    return rho / (3 * e)\n",
    "\n",
    "def p(rho, e, Y):\n",
    "    return Y * rho * e\n",
    "\n",
    "def p_eq(rho, e):\n",
    "    return p(rho, e, Y_eq(rho, e))\n",
    "\n",
    "def zeta(rho, e, epsilon):\n",
    "    return -epsilon * rho**2 / (3 * e) * (1 - (3 * e + rho**2) / (3 * rho * e))\n",
    "\n",
    "def Pi(rho, e, epsilon):\n",
    "    return - zeta(rho, e, epsilon) * theta\n",
    "\n",
    "def A(rho, e):\n",
    "    return e\n",
    "\n",
    "def B(rho, e):\n",
    "    return rho / 3\n",
    "\n",
    "def Gamma(rho, e, Y):\n",
    "    return A(rho, e) * Y - B(rho, e)\n",
    "\n",
    "def full_rhs(t, z, epsilon):\n",
    "    \"\"\"\n",
    "    In this case the state vector z = (rho, e, Y)^T.\n",
    "    \"\"\"\n",
    "    dzdt = np.zeros_like(z)\n",
    "    rho, e, Y = z\n",
    "    dzdt[0] = - rho * theta\n",
    "    dzdt[1] = - (e + p(rho, e, Y)) / rho * theta\n",
    "    dzdt[2] = - Gamma(rho, e, Y) / epsilon\n",
    "    return dzdt\n",
    "\n",
    "def average_rhs(t, z, epsilon):\n",
    "    \"\"\"\n",
    "    In this case the state vector z = (rho, e)^T as we deal with the reduced system.\n",
    "    \n",
    "    To get the leading order approximation, call with epsilon = 0.\n",
    "    \"\"\"\n",
    "    dzdt = np.zeros_like(z)\n",
    "    rho, e = z\n",
    "    dzdt[0] = - rho * theta\n",
    "    dzdt[1] = - (e + p_eq(rho, e) + Pi(rho, e, epsilon)) / rho * theta\n",
    "    return dzdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2367325",
   "metadata": {},
   "source": [
    "We will evolve up to $t=1$. We will start the system from equilibrium, so in the full case we use $Y(0) = Y_{\\text{eq}}(\\rho(0), e(0))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = 1\n",
    "ts = np.linspace(0, t_end, 200)\n",
    "Y0 = Y_eq(rho0, e0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2bac86",
   "metadata": {},
   "source": [
    "We can now check how the error in the internal energy varies as a function of $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39365dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = 0.5**np.arange(7, 15)\n",
    "errors1 = np.zeros_like(epsilons)\n",
    "errors2 = np.zeros_like(epsilons)\n",
    "soln_average = solve_ivp(average_rhs, [0, t_end], [rho0, e0], \n",
    "                         args=(0,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "for i, epsilon in enumerate(tqdm(epsilons)):\n",
    "    soln_full = solve_ivp(full_rhs, [0, t_end], [rho0, e0, Y0], \n",
    "                          args=(epsilon,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "    soln_bulk = solve_ivp(average_rhs, [0, t_end], [rho0, e0], \n",
    "                          args=(epsilon,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "    errors1[i] = abs(soln_full.sol(ts)[1, -1]-soln_average.sol(ts)[1, -1])\n",
    "    errors2[i] = abs(soln_full.sol(ts)[1, -1]-soln_bulk.sol(ts)[1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6512f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.polyfit(np.log(epsilons), np.log(errors1), 1)\n",
    "p2 = np.polyfit(np.log(epsilons), np.log(errors2), 1)\n",
    "fig, axes = plt.subplots(2, 1, figsize=half_width, sharex=True)\n",
    "axes[0].loglog(epsilons, errors1, 'kx', label=r'Errors, $\\infty$ fast')\n",
    "axes[0].loglog(epsilons, np.exp(p1[1])*epsilons**p1[0], 'b--', label=fr\"$\\propto \\epsilon^{{{p1[0]:.1f}}}$\")\n",
    "# axes[0].set_xlabel(r\"$\\epsilon$\")\n",
    "axes[0].legend()\n",
    "axes[1].loglog(epsilons, errors2, 'kx', label='Errors, Bulk')\n",
    "axes[1].loglog(epsilons, np.exp(p2[1])*epsilons**p2[0], 'b--', label=fr\"$\\propto \\epsilon^{{{p2[0]:.1f}}}$\")\n",
    "axes[1].set_xlabel(r\"$\\epsilon$\")\n",
    "axes[1].legend()\n",
    "fig.tight_layout()\n",
    "if save_plots:\n",
    "    fig.savefig('rel_no_bl_conv.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f3553",
   "metadata": {},
   "source": [
    "Now we plot the solutions for $\\rho, e$ as a function of time. We plot the full evolution of the species fraction to show its behaviour. We also plot the error in $e$, our primary observable, for both approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=full_width, sharex=True)\n",
    "axes[0, 0].plot(ts, soln_full.sol(ts)[0, :], label=\"Full\")\n",
    "axes[0, 0].plot(ts, soln_average.sol(ts)[0, :], label=r\"$\\infty$ fast\")\n",
    "axes[0, 0].plot(ts, soln_bulk.sol(ts)[0, :], label=r\"Bulk viscous\")\n",
    "axes[0, 0].set_xlim(0, 1)\n",
    "axes[0, 0].set_ylabel(r\"$\\rho$\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 1].plot(ts, soln_full.sol(ts)[1, :], label=\"Full\")\n",
    "axes[0, 1].plot(ts, soln_average.sol(ts)[1, :], label=r\"$\\infty$ fast\")\n",
    "axes[0, 1].plot(ts, soln_bulk.sol(ts)[1, :], label=r\"Bulk viscous\")\n",
    "axes[0, 1].set_xlim(0, 1)\n",
    "axes[0, 1].set_ylabel(r\"$e$\")\n",
    "axes[0, 1].legend()\n",
    "axes[1, 0].plot(ts, soln_full.sol(ts)[2, :], label=\"Full\")\n",
    "axes[1, 0].set_xlim(0, 1)\n",
    "axes[1, 0].set_xlabel(r\"$t$\")\n",
    "axes[1, 0].set_ylabel(r\"$Y$\")\n",
    "axes[1, 0].legend()\n",
    "axes[0, 1].legend()\n",
    "axes[1, 1].plot(ts, soln_full.sol(ts)[1, :] - soln_average.sol(ts)[1, :], label=r\"Full - $\\infty$ fast\")\n",
    "axes[1, 1].plot(ts, soln_full.sol(ts)[1, :] - soln_bulk.sol(ts)[1, :], label=r\"Full - Bulk\")\n",
    "axes[1, 1].set_xlim(0, 1)\n",
    "axes[1, 1].set_xlabel(r\"$t$\")\n",
    "axes[1, 1].set_ylabel(r\"Error\")\n",
    "axes[1, 1].legend()\n",
    "fig.tight_layout()\n",
    "if save_plots:\n",
    "    fig.savefig('rel_no_bl.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7350c8b",
   "metadata": {},
   "source": [
    "So we see the expected result. The bulk viscous approximation is both more accurate (even at \"large\" $\\epsilon$) and converges faster in the stiff limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8e82d",
   "metadata": {},
   "source": [
    "## Boundary layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037ed4a",
   "metadata": {},
   "source": [
    "In the previous example we started at equilibrium. This might seem reasonable during the inspiral. However, there are many physical and numerical effects that can locally kick the fluid element far from equilibrium. So we need to check the behaviour of the full system far from the equilibrium surface, and see how accurate the approximations are.\n",
    "\n",
    "Note that we use a pretty large value of $\\epsilon$ here for visual clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb63cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = 1\n",
    "\n",
    "epsilon = 1e-1\n",
    "soln_full = solve_ivp(full_rhs, [0, t_end], [rho0, e0, Y0],\n",
    "                      args=(epsilon,), dense_output=True)\n",
    "soln_average = solve_ivp(average_rhs, [0, t_end], [rho0, e0],\n",
    "                         args=(0,), dense_output=True)\n",
    "soln_bulk = solve_ivp(average_rhs, [0, t_end], [rho0, e0],\n",
    "                      args=(epsilon,), dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ccd6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, t_end, 200)\n",
    "fig, axes = plt.subplots(2, 2, figsize=full_width, sharex=True)\n",
    "axes[0, 0].plot(ts, soln_full.sol(ts)[0, :], label=\"Full\")\n",
    "axes[0, 0].plot(ts, soln_average.sol(ts)[0, :], label=r\"$\\infty$ fast\")\n",
    "axes[0, 0].plot(ts, soln_bulk.sol(ts)[0, :], label=r\"Bulk viscous\")\n",
    "axes[0, 0].set_xlim(0, 1)\n",
    "axes[0, 0].set_ylabel(r\"$\\rho$\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 1].plot(ts, soln_full.sol(ts)[1, :], label=\"Full\")\n",
    "axes[0, 1].plot(ts, soln_average.sol(ts)[1, :], label=r\"$\\infty$ fast\")\n",
    "axes[0, 1].plot(ts, soln_bulk.sol(ts)[1, :], label=r\"Bulk viscous\")\n",
    "axes[0, 1].set_xlim(0, 1)\n",
    "axes[0, 1].set_ylabel(r\"$e$\")\n",
    "axes[0, 1].legend()\n",
    "axes[1, 0].plot(ts, soln_full.sol(ts)[2, :], label=\"Full\")\n",
    "axes[1, 0].set_xlim(0, 1)\n",
    "axes[1, 0].set_xlabel(r\"$t$\")\n",
    "axes[1, 0].set_ylabel(r\"$Y$\")\n",
    "axes[1, 0].legend()\n",
    "axes[0, 1].legend()\n",
    "axes[1, 1].plot(ts, soln_full.sol(ts)[1, :] - soln_average.sol(ts)[1, :], label=r\"Full - $\\infty$ fast\")\n",
    "axes[1, 1].plot(ts, soln_full.sol(ts)[1, :] - soln_bulk.sol(ts)[1, :], label=r\"Full - Bulk\")\n",
    "axes[1, 1].set_xlim(0, 1)\n",
    "axes[1, 1].set_xlabel(r\"$t$\")\n",
    "axes[1, 1].set_ylabel(r\"Error\")\n",
    "axes[1, 1].legend()\n",
    "fig.tight_layout()\n",
    "if save_plots:\n",
    "    fig.savefig('rel_bl.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f1d17",
   "metadata": {},
   "source": [
    "We immediately see something that looks like a systematic error in the observable $e(1)$, due to the fast \"boundary layer\" behaviour as the species fraction $Y$ rapidly evolves to the equilibrium surface.\n",
    "\n",
    "We need to check what happens as the timescale $\\epsilon \\to 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39664717",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = 0.5**np.arange(7, 15)\n",
    "errors1 = np.zeros_like(epsilons)\n",
    "errors2 = np.zeros_like(epsilons)\n",
    "soln_average = solve_ivp(average_rhs, [0, t_end], [rho0, e0], \n",
    "                         args=(0,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "for i, epsilon in enumerate(tqdm(epsilons)):\n",
    "    soln_full = solve_ivp(full_rhs, [0, t_end], [rho0, e0, Y0], \n",
    "                          args=(epsilon,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "    soln_bulk = solve_ivp(average_rhs, [0, t_end], [rho0, e0], \n",
    "                          args=(epsilon,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "    errors1[i] = abs(soln_full.sol(ts)[1, -1]-soln_average.sol(ts)[1, -1])\n",
    "    errors2[i] = abs(soln_full.sol(ts)[1, -1]-soln_bulk.sol(ts)[1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.polyfit(np.log(epsilons), np.log(errors1), 1)\n",
    "p2 = np.polyfit(np.log(epsilons), np.log(errors2), 1)\n",
    "fig, axes = plt.subplots(2, 1, figsize=half_width, sharex=True)\n",
    "axes[0].loglog(epsilons, errors1, 'kx', label=r'Errors, $\\infty$ fast')\n",
    "axes[0].loglog(epsilons, np.exp(p1[1])*epsilons**p1[0], 'b--', label=fr\"$\\propto \\epsilon^{{{p1[0]:.1f}}}$\")\n",
    "# axes[0].set_xlabel(r\"$\\epsilon$\")\n",
    "axes[0].legend()\n",
    "axes[1].loglog(epsilons, errors2, 'kx', label='Errors, Bulk')\n",
    "axes[1].loglog(epsilons, np.exp(p2[1])*epsilons**p2[0], 'b--', label=fr\"$\\propto \\epsilon^{{{p2[0]:.1f}}}$\")\n",
    "axes[1].set_xlabel(r\"$\\epsilon$\")\n",
    "axes[1].legend()\n",
    "fig.tight_layout()\n",
    "if save_plots:\n",
    "    fig.savefig('rel_bl_conv.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581dea44",
   "metadata": {},
   "source": [
    "We see that the bulk viscous approximation is still (a tiny bit) better (in absolute terms) than the infinitely fast approach, but that the convergence rate is not better. The boundary layer has hidden the advantages of the bulk viscous approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ef510",
   "metadata": {},
   "source": [
    "## Matched asymptotics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd35d0",
   "metadata": {},
   "source": [
    "Going back to the original calculation, we can see that the problem here is due to the assumed form of the expansion. We wrote\n",
    "$$\n",
    "Y = \\sum_{n=0} \\epsilon^n Y_n.\n",
    "$$\n",
    "and found\n",
    "$$\n",
    "Y_0 = \\frac{B}{A} = Y_{\\text{eq}}(\\rho, e).\n",
    "$$\n",
    "This is inconsistent with the initial data (in the limit $\\epsilon \\to 0$) unless we start from equilibrium.\n",
    "\n",
    "To get around this we need to do a matched asymptotic expansion. We assume that the first calculation, the *outer expansion*, holds everywhere except in a small region of size $\\mathcal{O}(\\epsilon)$ near $t=0$. We then assume a different form of expansion holds in this region.\n",
    "\n",
    "The different expansion is constructed by introducing the fast time variable $\\tau = t / \\epsilon$ and re-writing the equations of motion as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{\\tau} \\rho &= - \\epsilon \\rho \\theta \\\\\n",
    "D_{\\tau} e &= - \\epsilon (e + p(\\rho, e, Y)) \\theta \\\\\n",
    "D_{\\tau} Y &= - \\Gamma(\\rho, e, Y).\n",
    "\\end{aligned}\n",
    "$$\n",
    "We again assume the expansion has the form\n",
    "$$\n",
    "Y = \\sum_{n=0} \\epsilon^n Y_n,\n",
    "$$\n",
    "but now $Y_n = Y_n(\\tau)$. This is our *inner* expansion.\n",
    "\n",
    "Again we look at the species fraction evolution equation by order in $\\epsilon$. This gives\n",
    "$$\n",
    "D_{\\tau} Y_0 + A Y_0 = B\n",
    "$$\n",
    "from which we find\n",
    "$$\n",
    "Y_0 = \\frac{B}{A} + C_0 e^{-A \\tau} = Y_{\\text{eq}} + C_0 e^{-A \\tau}.\n",
    "$$\n",
    "Now we can use the initial data to fix $C_0 = Y(0) - Y_{\\text{eq}}(0) = \\Delta Y$, and this expansion must be consistent with the initial data.\n",
    "\n",
    "Next we solve for the higher order terms, finding\n",
    "$$\n",
    "Y_n = C_n e^{-A \\tau}.\n",
    "$$\n",
    "We won't need these later, but they show how a higher-order approximation could be constructed.\n",
    "\n",
    "We then (again) substitute into the pressure, expanding about equilibrium, to find\n",
    "$$\n",
    "p(\\rho, e, Y) = p_{\\text{eq}} + \\Delta Y \\, \\partial_Y p \\, e^{-A \\tau} + \\mathcal{O}(\\Delta Y^2, \\epsilon).\n",
    "$$\n",
    "\n",
    "From this we can evaluate the internal energy at the time $\\tau = T$, meaning $t =  \\epsilon T$, for both our inner and outer expansions. First, for the outer expansion, we have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "e(t = \\epsilon T) &= e(0) + \\int_0^{\\epsilon T} \\text{d}t \\, D_t e \\\\\n",
    "&= e(0) - \\int_0^{\\epsilon T} \\text{d}t \\, (e + p_{\\text{eq}} + \\Pi) \\theta + \\mathcal{O}(\\epsilon^2) \\\\\n",
    "&= e(0) (1 - \\epsilon \\theta) - \\epsilon T p_{\\text{eq}} \\theta + \\mathcal{O}(\\epsilon^2).\n",
    "\\end{aligned}\n",
    "$$\n",
    "Next, for the inner expansion, we have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "e(\\tau = T) &= e(0) + \\int_0^{T} \\text{d} \\tau \\, D_{\\tau} e \\\\\n",
    "&= e(0) - \\int_0^{T} \\text{d} \\tau \\, \\epsilon (e + p_{\\text{eq}} + \\Delta Y \\, \\partial_Y p \\, e^{-A \\tau}) \\theta + \\mathcal{O}(\\epsilon^2) \\\\\n",
    "&= e(0) (1 - \\epsilon \\theta) - \\epsilon T p_{\\text{eq}} \\theta + \\epsilon \\frac{\\Delta Y \\, \\partial_Y p}{A} \\theta \\left( 1 - e^{-A T} \\right) + \\mathcal{O}(\\epsilon^2).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore, in order to match the inner and outer expansion at some time $\\tau = T$, the \"initial value\" $e(0)$ for the outer expansion has to be modified to\n",
    "$$\n",
    "e(0) \\to e(0) - \\epsilon \\frac{\\Delta Y \\, \\partial_Y p}{A} \\theta.\n",
    "$$\n",
    "The term in the inner expansion proportional to $e^{-A T}$ is dropped as $\\tau = \\epsilon t$, so at finite $T$ and in the limit $\\epsilon \\to 0$ this term is exponentially small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a74fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = 1\n",
    "\n",
    "epsilon = 1e-1\n",
    "\n",
    "def dYp(rho, e, Y):\n",
    "    return rho * e\n",
    "\n",
    "e0_modified = e0 - epsilon * theta * (Y0 - Y_eq(rho0, e0)) * dYp(rho0, e0, Y0) / (A(rho0, e0))\n",
    "\n",
    "soln_full = solve_ivp(full_rhs, [0, t_end], [rho0, e0, Y0],\n",
    "                      args=(epsilon,), dense_output=True)\n",
    "soln_average = solve_ivp(average_rhs, [0, t_end], [rho0, e0],\n",
    "                         args=(0,), dense_output=True)\n",
    "soln_bulk = solve_ivp(average_rhs, [0, t_end], [rho0, e0_modified],\n",
    "                      args=(epsilon,), dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, t_end, 200)\n",
    "fig, axes = plt.subplots(2, 2, figsize=full_width, sharex=True)\n",
    "axes[0, 0].plot(ts, soln_full.sol(ts)[0, :], label=\"Full\")\n",
    "axes[0, 0].plot(ts, soln_average.sol(ts)[0, :], label=r\"$\\infty$ fast\")\n",
    "axes[0, 0].plot(ts, soln_bulk.sol(ts)[0, :], label=r\"Bulk viscous\")\n",
    "axes[0, 0].set_xlim(0, 1)\n",
    "axes[0, 0].set_ylabel(r\"$\\rho$\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 1].plot(ts, soln_full.sol(ts)[1, :], label=\"Full\")\n",
    "axes[0, 1].plot(ts, soln_average.sol(ts)[1, :], label=r\"$\\infty$ fast\")\n",
    "axes[0, 1].plot(ts, soln_bulk.sol(ts)[1, :], label=r\"Bulk viscous\")\n",
    "axes[0, 1].set_xlim(0, 1)\n",
    "axes[0, 1].set_ylabel(r\"$e$\")\n",
    "axes[0, 1].legend()\n",
    "axes[1, 0].plot(ts, soln_full.sol(ts)[2, :], label=\"Full\")\n",
    "axes[1, 0].set_xlim(0, 1)\n",
    "axes[1, 0].set_xlabel(r\"$t$\")\n",
    "axes[1, 0].set_ylabel(r\"$Y$\")\n",
    "axes[1, 0].legend()\n",
    "axes[0, 1].legend()\n",
    "axes[1, 1].plot(ts, soln_full.sol(ts)[1, :] - soln_average.sol(ts)[1, :], label=r\"Full - $\\infty$ fast\")\n",
    "axes[1, 1].plot(ts, soln_full.sol(ts)[1, :] - soln_bulk.sol(ts)[1, :], label=r\"Full - Bulk\")\n",
    "axes[1, 1].set_xlim(0, 1)\n",
    "axes[1, 1].set_xlabel(r\"$t$\")\n",
    "axes[1, 1].set_ylabel(r\"Error\")\n",
    "axes[1, 1].legend()\n",
    "fig.tight_layout()\n",
    "if save_plots:\n",
    "    fig.savefig('rel_bl_correction.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc460d5",
   "metadata": {},
   "source": [
    "We immediately see a huge improvement for the bulk viscous approximation (which is the only case where the initial data is modified).\n",
    "\n",
    "We next check convergence with $\\epsilon$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4706c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = 0.5**np.arange(7, 15)\n",
    "errors1 = np.zeros_like(epsilons)\n",
    "errors2 = np.zeros_like(epsilons)\n",
    "soln_average = solve_ivp(average_rhs, [0, t_end], [rho0, e0], \n",
    "                         args=(0,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "for i, epsilon in enumerate(tqdm(epsilons)):\n",
    "    e0_modified = e0 - epsilon * theta * (Y0 - Y_eq(rho0, e0)) * dYp(rho0, e0, Y0) / (rho0 * A(rho0, e0))\n",
    "    \n",
    "    soln_full = solve_ivp(full_rhs, [0, t_end], [rho0, e0, Y0], \n",
    "                          args=(epsilon,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "    soln_bulk = solve_ivp(average_rhs, [0, t_end], [rho0, e0_modified], \n",
    "                          args=(epsilon,), dense_output=True,\n",
    "                         rtol=1e-6, atol=1e-8)\n",
    "    errors1[i] = abs(soln_full.sol(ts)[1, -1]-soln_average.sol(ts)[1, -1])\n",
    "    errors2[i] = abs(soln_full.sol(ts)[1, -1]-soln_bulk.sol(ts)[1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a315814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.polyfit(np.log(epsilons), np.log(errors1), 1)\n",
    "p2 = np.polyfit(np.log(epsilons), np.log(errors2), 1)\n",
    "fig, axes = plt.subplots(2, 1, figsize=half_width)\n",
    "axes[0].loglog(epsilons, errors1, 'kx', label=r'Errors, $\\infty$ fast')\n",
    "axes[0].loglog(epsilons, np.exp(p1[1])*epsilons**p1[0], 'b--', label=fr\"$\\propto \\epsilon^{{{p1[0]:.1f}}}$\")\n",
    "# axes[0].set_xlabel(r\"$\\epsilon$\")\n",
    "axes[0].legend()\n",
    "axes[1].loglog(epsilons, errors2, 'kx', label='Errors, Bulk')\n",
    "axes[1].loglog(epsilons, np.exp(p2[1])*epsilons**p2[0], 'b--', label=fr\"$\\propto \\epsilon^{{{p2[0]:.1f}}}$\")\n",
    "axes[1].set_xlabel(r\"$\\epsilon$\")\n",
    "axes[1].legend()\n",
    "fig.tight_layout()\n",
    "if save_plots:\n",
    "    fig.savefig('rel_bl_correction_conv.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e729434",
   "metadata": {},
   "source": [
    "We see immediately that matching to the boundary layer, and hence modifying the internal energy, is necessary in order to capture the second order (in deviations from equilibrium) effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ff098",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727faf34",
   "metadata": {},
   "source": [
    "Bulk viscosity driven by nuclear reactions is a second order effect in deviations from (chemical) equilibrium. Models or numerical methods that enforce chemical equilibrium directly, without correcting for the impact on the internal energy, will miss the boundary layer effects, and therefore will be unable to make any statement about the impact of bulk viscosity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ea8be",
   "metadata": {},
   "source": [
    "# Extra stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf0522",
   "metadata": {},
   "source": [
    "#### PDEs\n",
    "\n",
    "Need to think how this goes for PDEs.\n",
    "\n",
    "Take Cattaneo written as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\partial_t T + \\partial_x q &= 0 \\\\\n",
    "  \\partial_t q &= \\epsilon^{-1} \\left( - q - \\kappa \\partial_x T \\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "The outer expansion gives\n",
    "$$\n",
    "q_0 = - \\kappa \\partial_x T\n",
    "$$\n",
    "and\n",
    "$$\n",
    "q_1 = - \\partial_t q_0 = \\kappa \\partial_x \\left( - \\partial_x T \\right).\n",
    "$$\n",
    "This gives\n",
    "$$\n",
    "\\partial_t T = \\kappa \\partial^{(2)}_x T + \\epsilon \\kappa^2 \\partial^{(4)}_x T\n",
    "$$\n",
    "as expected (check the signs of the last term, although it is irrelevant to this calculation).\n",
    "\n",
    "The inner expansion gives the equations of motion as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\partial_{\\tau} T + \\epsilon \\partial_x q &= 0 \\\\\n",
    "  \\partial_{\\tau} q &=  - q - \\kappa \\partial_x T.\n",
    "\\end{aligned}\n",
    "$$\n",
    "The power series now gives that $T$ is independent of $\\tau$ to leading order and hence\n",
    "$$\n",
    "  \\partial_{\\tau} q_0 =  - q_0 - \\kappa \\partial_x T\n",
    "$$\n",
    "integrates directly to\n",
    "$$\n",
    "q_0 = C_0 e^{-\\tau} - \\kappa \\partial_x T.\n",
    "$$\n",
    "Comparing to the initial data $q(x, 0)$ and writing $\\Delta q = q(x, 0) + \\kappa \\partial_x T(x, 0)$ we get\n",
    "$$\n",
    "q_0 = \\Delta q \\, e^{-\\tau} - \\kappa \\partial_x T.\n",
    "$$\n",
    "From this we have\n",
    "$$\n",
    "\\partial_{\\tau} T = \\epsilon \\left( -e^{-\\tau} \\partial_x \\Delta q + \\kappa \\partial^{(2)}_x T \\right).\n",
    "$$\n",
    "\n",
    "The standard matching as above will then give us that\n",
    "$$\n",
    "T(x, 0) \\to T(x, 0) - \\partial_x \\Delta q.\n",
    "$$\n",
    "\n",
    "I think exactly this form of the calculation (where the matching term comes from integrating a linear first order ODE giving the $e^{-\\tau}$ term) will follow whenever the fast equation has a relaxation term that is linear in the fast variable. This holds true for the MIS equations for the bulk and shear case, I believe. The heat equation is less obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26a9e8",
   "metadata": {},
   "source": [
    "#### Constraints\n",
    "\n",
    "The \"real\" problem relies on detailed balance of the radiation species vs the other variables. I think the way to model this is to say that, in addition to the slow and fast equations of motion, that there should also be a constraint $h(x, y)$ that has to hold on the fast (or maybe slow?) time. We then add this constraint to the appropriate equation(s) of motion using a Lagrange multiplier. When the expansion in terms of the fast variables is done there should be a correction term which can be matched."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
